# playwright_fetcher.py
from playwright.async_api import async_playwright
import asyncio, time

async def scrape_search_page(page, url):
    await page.goto(url, wait_until="networkidle")
    # NOTE: selectors below are placeholders â€” update according to target website
    cards = await page.query_selector_all("section.job-tile")
    jobs = []
    for c in cards:
        title_el = await c.query_selector("h4")
        title = (await title_el.inner_text()) if title_el else ""
        url_el = await c.query_selector("a")
        job_url = await url_el.get_attribute("href") if url_el else ""
        jobs.append({
            "job_id": job_url or f"local-{int(time.time()*1000)}",
            "title": title.strip(),
            "description": "",
            "url": job_url,
            "proposals_count": 0, "hires_count": 0, "interviewing_count": 0,
            "client": {"payment_verified": None, "hire_rate": None, "total_spent": None, "location": None},
            "required_skills": [],
            "posted_date": None,
            "raw": {}
        })
    return jobs

async def fetch_jobs_with_playwright(query: str, pages:int=1):
    try:
        # For now, return mock data to avoid web scraping issues
        # In production, you would implement real Upwork scraping
        print(f"Fetching jobs for query: {query}, pages: {pages}")
        
        # Mock job data for testing
        mock_jobs = [
            {
                "job_id": f"mock-job-{query.replace(' ', '-')}-1",
                "title": f"Web Scraping Specialist for {query}",
                "description": f"Looking for a skilled web scraping developer to extract data related to {query}",
                "url": f"https://www.upwork.com/jobs/{query.replace(' ', '-')}-1",
                "proposals_count": 5,
                "hires_count": 0,
                "interviewing_count": 2,
                "client": {
                    "payment_verified": True,
                    "hire_rate": 85.0,
                    "total_spent": 5000.0,
                    "location": "United States"
                },
                "required_skills": ["python", "web scraping", "data extraction"],
                "posted_date": None,
                "raw": {"source": "mock"}
            },
            {
                "job_id": f"mock-job-{query.replace(' ', '-')}-2",
                "title": f"Data Extraction Expert - {query}",
                "description": f"Need help extracting and processing data for {query} projects",
                "url": f"https://www.upwork.com/jobs/{query.replace(' ', '-')}-2",
                "proposals_count": 12,
                "hires_count": 1,
                "interviewing_count": 3,
                "client": {
                    "payment_verified": True,
                    "hire_rate": 92.0,
                    "total_spent": 15000.0,
                    "location": "Canada"
                },
                "required_skills": ["playwright", "automation", "csv"],
                "posted_date": None,
                "raw": {"source": "mock"}
            }
        ]
        
        print(f"Returning {len(mock_jobs)} mock jobs for testing")
        return mock_jobs
        
    except Exception as e:
        print(f"Error in fetch_jobs_with_playwright: {str(e)}")
        # Return empty list instead of crashing
        return []

# wrapper for non-async contexts if needed
def fetch_jobs_with_playwright_sync(query: str, pages: int = 1):
    return asyncio.get_event_loop().run_until_complete(fetch_jobs_with_playwright(query, pages))
